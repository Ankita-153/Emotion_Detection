{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f975ed68-d86b-439e-bf6a-333b26c5ea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Emotion Detection System\n",
      "1. Process Image\n",
      "2. Process Video\n",
      "3. Process Webcam\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose an option (1/2/3):  1\n",
      "Enter full image path:  C:\\Users\\Ankita Borkar\\Downloads\\obama.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import dlib\n",
    "import uuid\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Load emotion detection model\n",
    "model = load_model(r\"C:\\Users\\Ankita Borkar\\OneDrive\\Desktop\\Emotion Detetction\\emotion_model.h5\")\n",
    "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "# MediaPipe Face Detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n",
    "\n",
    "# Globals for tracking\n",
    "trackers = {}\n",
    "face_emotion_history = {}\n",
    "\n",
    "# Emotion prediction\n",
    "def predict_emotion(face_img):\n",
    "    gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
    "    resized = cv2.resize(gray, (48, 48))\n",
    "    normalized = resized / 255.0\n",
    "    reshaped = np.reshape(normalized, (1, 48, 48, 1))\n",
    "    result = model.predict(reshaped, verbose=0)\n",
    "    label_idx = int(np.argmax(result))\n",
    "    confidence = float(np.max(result)) * 100\n",
    "    return emotion_labels[label_idx], confidence\n",
    "\n",
    "# Log to CSV\n",
    "def log_emotion(frame_id, face_id, emotion, confidence):\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    with open(\"emotion_log.csv\", mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([frame_id, timestamp, face_id, emotion, f\"{confidence:.2f}\"])\n",
    "\n",
    "# IoU for tracker matching\n",
    "def iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[0] + boxA[2], boxB[0] + boxB[2])\n",
    "    yB = min(boxA[1] + boxA[3], boxB[1] + boxB[3])\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    boxAArea = boxA[2] * boxA[3]\n",
    "    boxBArea = boxB[2] * boxB[3]\n",
    "    return interArea / float(boxAArea + boxBArea - interArea + 1e-5)\n",
    "\n",
    "# For video & webcam\n",
    "def detect_and_track_faces(frame, frame_id):\n",
    "    global trackers, face_emotion_history\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    detections = face_detection.process(rgb_frame)\n",
    "    updated_trackers = {}\n",
    "\n",
    "    # Update trackers\n",
    "    for face_id, tracker in trackers.items():\n",
    "        tracker.update(frame)\n",
    "        pos = tracker.get_position()\n",
    "        x, y, w, h = int(pos.left()), int(pos.top()), int(pos.width()), int(pos.height())\n",
    "        x2, y2 = x + w, y + h\n",
    "\n",
    "        face_roi = frame[y:y2, x:x2]\n",
    "        if face_roi.size > 0:\n",
    "            emotion, confidence = predict_emotion(face_roi)\n",
    "            face_emotion_history[face_id] = (emotion, confidence)\n",
    "            log_emotion(frame_id, face_id, emotion, confidence)\n",
    "            label = f\"ID: {face_id[:4]} | {emotion} ({confidence:.1f}%)\"\n",
    "            cv2.rectangle(frame, (x, y), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "\n",
    "        updated_trackers[face_id] = tracker\n",
    "\n",
    "    # New detections\n",
    "    if detections and detections.detections:\n",
    "        ih, iw, _ = frame.shape\n",
    "        for det in detections.detections:\n",
    "            bbox = det.location_data.relative_bounding_box\n",
    "            x, y, w, h = int(bbox.xmin * iw), int(bbox.ymin * ih), int(bbox.width * iw), int(bbox.height * ih)\n",
    "            new_box = (x, y, w, h)\n",
    "\n",
    "            matched = False\n",
    "            for tracker in updated_trackers.values():\n",
    "                pos = tracker.get_position()\n",
    "                existing_box = (int(pos.left()), int(pos.top()), int(pos.width()), int(pos.height()))\n",
    "                if iou(new_box, existing_box) > 0.4:\n",
    "                    matched = True\n",
    "                    break\n",
    "\n",
    "            if not matched:\n",
    "                new_tracker = dlib.correlation_tracker()\n",
    "                rect = dlib.rectangle(x, y, x + w, y + h)\n",
    "                new_tracker.start_track(frame, rect)\n",
    "                new_face_id = str(uuid.uuid4())\n",
    "                updated_trackers[new_face_id] = new_tracker\n",
    "                face_emotion_history[new_face_id] = (\"Unknown\", 0.0)\n",
    "\n",
    "    trackers = updated_trackers\n",
    "    return frame\n",
    "\n",
    "# Fixed image processor\n",
    "def process_image():\n",
    "    path = input(\"Enter full image path: \").strip().strip('\"')\n",
    "    if not os.path.exists(path):\n",
    "        print(\"[ERROR] Image not found!\")\n",
    "        return\n",
    "\n",
    "    image = cv2.imread(path)\n",
    "    if image is None:\n",
    "        print(\"[ERROR] Could not open image.\")\n",
    "        return\n",
    "\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    detections = face_detection.process(rgb_image)\n",
    "\n",
    "    if detections and detections.detections:\n",
    "        ih, iw, _ = image.shape\n",
    "        for det in detections.detections:\n",
    "            bbox = det.location_data.relative_bounding_box\n",
    "            x, y, w, h = int(bbox.xmin * iw), int(bbox.ymin * ih), int(bbox.width * iw), int(bbox.height * ih)\n",
    "            x, y = max(0, x), max(0, y)\n",
    "            x2, y2 = min(iw, x + w), min(ih, y + h)\n",
    "\n",
    "            face_roi = image[y:y2, x:x2]\n",
    "            if face_roi.size > 0:\n",
    "                emotion, confidence = predict_emotion(face_roi)\n",
    "                label = f\"{emotion} ({confidence:.1f}%)\"\n",
    "                cv2.rectangle(image, (x, y), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "    else:\n",
    "        print(\"[INFO] No face detected in image.\")\n",
    "\n",
    "    cv2.imshow(\"Emotion Detection - Image\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Video\n",
    "def process_video():\n",
    "    path = input(\"Enter full video path: \").strip().strip('\"')\n",
    "    if not os.path.exists(path):\n",
    "        print(\"[ERROR] Video not found!\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frame_id = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = detect_and_track_faces(frame, frame_id)\n",
    "        cv2.imshow(\"Emotion Detection - Video\", frame)\n",
    "        frame_id += 1\n",
    "\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Webcam\n",
    "def process_webcam():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"[ERROR] Could not access webcam.\")\n",
    "        return\n",
    "\n",
    "    frame_id = 0\n",
    "    print(\"[INFO] Press 'q' to quit webcam.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = detect_and_track_faces(frame, frame_id)\n",
    "        cv2.imshow(\"Emotion Detection - Webcam\", frame)\n",
    "        frame_id += 1\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Menu\n",
    "def main():\n",
    "    print(\"\\nEmotion Detection System\")\n",
    "    print(\"1. Process Image\")\n",
    "    print(\"2. Process Video\")\n",
    "    print(\"3. Process Webcam\")\n",
    "    choice = input(\"Choose an option (1/2/3): \").strip()\n",
    "\n",
    "    if choice == '1':\n",
    "        process_image()\n",
    "    elif choice == '2':\n",
    "        process_video()\n",
    "    elif choice == '3':\n",
    "        process_webcam()\n",
    "    else:\n",
    "        print(\"Invalid choice.\")\n",
    "\n",
    "# Create CSV if needed\n",
    "if not os.path.exists(\"emotion_log.csv\"):\n",
    "    with open(\"emotion_log.csv\", mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Frame ID\", \"Timestamp\", \"Face ID\", \"Emotion\", \"Confidence\"])\n",
    "\n",
    "# Run\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997c32f8-33b6-4bdc-bfe0-498071a8d5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5211d072-f37d-41a2-ac1a-2b7da07ec87e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (faceenv)",
   "language": "python",
   "name": "faceenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
